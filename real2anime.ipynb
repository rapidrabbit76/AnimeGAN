{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    image = image / 255\n",
    "    image = (image - 0.5) / 0.5\n",
    "    return image\n",
    "\n",
    "def denormalize(image):\n",
    "    image = (image * 0.5) + 0.5\n",
    "    image = image * 255\n",
    "    image = torch.clip(image, min=0, max=255.0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load Generator from source code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Generator\n",
    "\n",
    "CKPT_PATH = \"./src/ckpt_E:213.ckpt.pth\"\n",
    "\n",
    "assert os.path.exists(CKPT_PATH), f\"{CKPT_PATH} Not Found\"\n",
    "\n",
    "\n",
    "class args:\n",
    "    image_channels = 3\n",
    "    g_dim = 32\n",
    "\n",
    "\n",
    "model = Generator(args())\n",
    "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt[\"gen\"])\n",
    "model = model.to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load Generator from torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TORCHSCRIPT_PATH = './src/AnimeGAN.pt.zip'\n",
    "assert os.path.exists(TORCHSCRIPT_PATH), f\"{TORCHSCRIPT_PATH} Not Found\"\n",
    "\n",
    "model = torch.jit.load(TORCHSCRIPT_PATH)\n",
    "model = model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Photo Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "TARGET_PHOTO_FILE_PATH = \"./src/temp.png\"\n",
    "! curl -o {TARGET_PHOTO_FILE_PATH} \"https://scontent-ssn1-1.xx.fbcdn.net/v/t31.18172-8/22382411_10159396144300134_2436048902354400141_o.jpg?_nc_cat=104&ccb=1-5&_nc_sid=730e14&_nc_ohc=MvqDCYs75IwAX-F5ALB&_nc_ht=scontent-ssn1-1.xx&oh=00_AT9MswhisOTffXl0suHiS3_ue_uyx9RRjiJEzBck9mBmQQ&oe=626724FD\"\n",
    "\n",
    "assert os.path.exists(\n",
    "    TARGET_PHOTO_FILE_PATH\n",
    "), f\"{TARGET_PHOTO_FILE_PATH} not Found\"\n",
    "\n",
    "image = cv2.imread(TARGET_PHOTO_FILE_PATH)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "Image.fromarray(image).show()\n",
    "image = np.expand_dims(image, 0)\n",
    "image = np.transpose(image, [0, 3, 2, 1])\n",
    "image = image.astype(np.float32)\n",
    "image = normalize(torch.from_numpy(image))\n",
    "image = image.to(DEVICE)\n",
    "with torch.cuda.amp.autocast():\n",
    "    image = model(image)\n",
    "\n",
    "image = denormalize(image).cpu().numpy()\n",
    "image = np.transpose(image, [0, 3, 2, 1])\n",
    "image = image.astype(np.uint8)\n",
    "Image.fromarray(image[0]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Video Convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Video file download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "TARGET_VIDEO_FILE_PATH = \"./src/video/sample.mp4\"\n",
    "SAVE_VIDEO_DIR = \"./src/video/\"\n",
    "\n",
    "# download video file from youtube\n",
    "! yt-dlp -f 299+140 https://www.youtube.com/watch?v=KoMw2Qa5bQs  -o {TARGET_VIDEO_FILE_PATH}\n",
    "\n",
    "assert os.path.exists(\n",
    "    TARGET_VIDEO_FILE_PATH\n",
    "), f\"{TARGET_VIDEO_FILE_PATH} Not Found\"\n",
    "\n",
    "os.makedirs(SAVE_VIDEO_DIR, exist_ok=True)\n",
    "\n",
    "basename = os.path.basename(TARGET_VIDEO_FILE_PATH)\n",
    "basename = os.path.splitext(basename)[0]\n",
    "\n",
    "SAVE_VIDEO_FILE_PATH = os.path.join(SAVE_VIDEO_DIR, basename + \"_anime_wo_audio.mp4\")\n",
    "VIDEO_WITH_AUDIO_FILE = os.path.join(\n",
    "    SAVE_VIDEO_DIR, basename + \"_anime.mp4\"\n",
    ")\n",
    "\n",
    "temp = tempfile.NamedTemporaryFile(suffix=\".wav\")\n",
    "AUDIO_PATH = temp.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Video file setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.video.io.ffmpeg_writer as ffmpeg_writer\n",
    "\n",
    "video_clip = VideoFileClip(TARGET_VIDEO_FILE_PATH)\n",
    "audio_clip = video_clip.audio\n",
    "audio_clip.write_audiofile(AUDIO_PATH)\n",
    "total_frames = int(video_clip.duration * video_clip.fps)\n",
    "\n",
    "video_writer = ffmpeg_writer.FFMPEG_VideoWriter(\n",
    "    SAVE_VIDEO_FILE_PATH,\n",
    "    video_clip.size,\n",
    "    video_clip.fps,\n",
    "    codec=\"libx264\",\n",
    "    preset=\"medium\",\n",
    "    bitrate=\"5500k\",\n",
    "    threads=8,\n",
    "    ffmpeg_params=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Convert Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust BATCH_SIZE to your GPU vRAM\n",
    "BATCH_SIZE = 6\n",
    "buf = []\n",
    "\n",
    "assert os.path.exists(AUDIO_PATH), f\"{AUDIO_PATH} Not Found\"\n",
    "\n",
    "for idx, frame in enumerate(tqdm(video_clip.iter_frames(), total=total_frames)):\n",
    "    buf.append(frame)\n",
    "\n",
    "    if len(buf) < BATCH_SIZE and idx < total_frames - 1:\n",
    "        continue\n",
    "\n",
    "    images = [np.expand_dims(image, 0) for image in buf]\n",
    "    images = np.concatenate(images, 0)\n",
    "    images = np.transpose(images, [0, 3, 2, 1])\n",
    "    images = images.astype(np.float32)\n",
    "\n",
    "    images = normalize(torch.from_numpy(images))\n",
    "    images = images.to(DEVICE)\n",
    "\n",
    "    # inference\n",
    "    with torch.cuda.amp.autocast():\n",
    "        processed_image = model(images)\n",
    "\n",
    "    processed_image = denormalize(processed_image)\n",
    "    processed_image = processed_image.cpu().numpy()\n",
    "    processed_image = np.transpose(processed_image, [0, 3, 2, 1])\n",
    "    processed_image = processed_image.astype(np.uint8)\n",
    "    frames = [frame for frame in processed_image]\n",
    "    for frame in frames:\n",
    "        video_writer.write_frame(frame)\n",
    "    buf.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix audio\n",
    "! ffmpeg -i {SAVE_VIDEO_FILE_PATH} -i {AUDIO_PATH} {VIDEO_WITH_AUDIO_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VIDEO = \"src/video/sample.mp4\"\n",
    "GIF_PATH = 'src/gif/sample_origin.gif'\n",
    "\n",
    "TARGET_ANIME_VIDEO = \"src/video/sample_anime.mp4\"\n",
    "ANIME_GIF_PATH = \"src/gif/sample_anime.gif\"\n",
    "\n",
    "! ffmpeg -i {TARGET_VIDEO} -vf scale=320:-1 -r 10 -f image2pipe -vcodec ppm - | convert -delay 10 -loop 0 - {GIF_PATH}\n",
    "! ffmpeg -i {TARGET_ANIME_VIDEO} -vf scale=720:-1 -r 10 -f image2pipe -vcodec ppm - | convert -delay 10 -loop 0 - {ANIME_GIF_PATH}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7cc8ada418834a01918b1de68174e16f6a1e4b03ace36c7e298c692ef1de636"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
